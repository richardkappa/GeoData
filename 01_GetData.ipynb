{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"D:/GeoData/\"\n",
    "Main_CRS = \"EPSG:27700\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data into a standard structrue for the geopandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Import_Points(infile, inputs):\n",
    "    #print(inputs[\"Type\"])\n",
    "    #Get the before and after columns names\n",
    "    usecols = list(filter(None,list(inputs.values())[1:8]))\n",
    "    col_names = list({key: value for key, value in inputs.items() if value in usecols}.keys())\n",
    "    \n",
    "    #Get the data types\n",
    "    t_dtypes = {key: value for key, value in dtypes.items() if key in col_names}\n",
    "    dtypes_in = {inputs[k]:v for k, v in t_dtypes.items()}\n",
    "    dtype_out = {key: value for key, value in dtypes.items() if key in col_names}\n",
    "\n",
    "    #Import the data\n",
    "    df = pd.read_csv(infile, usecols=usecols, encoding = \"ISO-8859-1\", dtype=dtypes_in) \n",
    "\n",
    "    #Reformat ready for next step\n",
    "    df.columns = col_names\n",
    "    df = df.astype(dtype_out)\n",
    "\n",
    "    df[\"Type\"] = inputs[\"Type\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source data\n",
    "rail_infile = root_path + \"NaPTANcsv/RailReferences.csv\"\n",
    "rail_inputs = {\"Type\":\"RailwayStations\", \"Name\":\"StationName\", \"Easting\":\"Easting\", \"Northing\":\"Northing\"}\n",
    "\n",
    "ferry_infile = root_path + \"NaPTANcsv/FerryReferences.csv\"\n",
    "ferry_inputs = {\"Type\":\"FerryTerminals\", \"Name\":\"Name\", \"Easting\":\"Easting\", \"Northing\":\"Northing\"}\n",
    "\n",
    "bus_infile = root_path + \"NaPTANcsv/Stops.csv\"\n",
    "bus_inputs = {\"Type\":\"BusStops\", \"Name\":\"CommonName\", \"Easting\":\"Easting\", \"Northing\":\"Northing\"}\n",
    "\n",
    "acc2020_infile = root_path + \"RoadSafety/dft-road-casualty-statistics-accident-2020.csv\"\n",
    "acc2020_inputs = {\"Type\":\"RoadAccidents\", \"Name\":\"accident_reference\", \"Easting\":\"location_easting_osgr\", \"Northing\":\"location_northing_osgr\"}\n",
    "\n",
    "NSPL_infile = root_path + \"NSPL_NOV_2020_UK/Data/NSPL_NOV_2020_UK.csv\"\n",
    "NSPL_inputs = {\"Type\":\"Postcodes\", \"Name\":\"pcd\", \"Easting\":\"oseast1m\", \"Northing\":\"osnrth1m\"}\n",
    "\n",
    "#NSUL_Infile defined below\n",
    "NSUL_inputs = {\"Type\":\"UDPRNs\", \"Name\":\"uprn\", \"Easting\":\"gridgb1e\", \"Northing\":\"gridgb1n\", \"Details_Str\":\"pcds\"}\n",
    "\n",
    "point_pairs = [[rail_infile, rail_inputs],\n",
    "[ferry_infile, ferry_inputs],\n",
    "[bus_infile, bus_inputs],\n",
    "[acc2020_infile, acc2020_inputs],\n",
    "[NSPL_infile,NSPL_inputs]]\n",
    "\n",
    "NSUL_Pairs = [[root_path + \"NSUL_OCT_2020/Data/\" + str(i), NSUL_inputs] for i in os.listdir(\"D:/GeoData/NSUL_OCT_2020/Data\") if \".csv\" in i]\n",
    "\n",
    "point_pairs = point_pairs + NSUL_Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the standard structure\n",
    "Points_of_Interest = pd.DataFrame({\"Type\":\"\", \"Name\":\"\", \"Details_Str\":\"\", \"Details_Float\":0, \"Easting\":0, \"Northing\":0}, index=[0])\n",
    "dtypes = {\"Type\":\"str\", \"Name\":\"str\", \"Details_Str\":\"str\", \"Details_Float\":np.float64, \"Easting\":np.float64, \"Northing\":np.float64}\n",
    "Points_of_Interest = Points_of_Interest.astype(dtypes)\n",
    "Points_of_Interest = Points_of_Interest.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in point_pairs:\n",
    "    Points_of_Interest = Points_of_Interest.append(Import_Points(l[0], l[1]), ignore_index=True)\n",
    "\n",
    "#remove the spaces from the postcode\n",
    "Points_of_Interest.loc[Points_of_Interest[\"Type\"]==\"Postcodes\", \"Name\"] = Points_of_Interest.loc[Points_of_Interest[\"Type\"]==\"Postcodes\", \"Name\"].astype(str).str.replace(\" \",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the land registry data, merge on the postcodes from NSPL data then add to the main file\n",
    "LReg_Names = ['Transaction_unique_identifier', 'Price', 'Date_of_Transfer', 'Postcode', 'Property_Type', \n",
    "              'Old_New', 'Duration', 'PAON', 'SAON', 'Street', 'Locality', 'Town_City', 'District', 'County', \n",
    "              'PPDCategory_Type', 'Record_Status_monthly_file_only']\n",
    "\n",
    "usecols = ['Transaction_unique_identifier', 'Price', 'Date_of_Transfer', 'Postcode', 'Property_Type', 'Old_New', 'Duration']\n",
    "\n",
    "LReg_Data2020 = pd.read_csv(root_path + \"LandReg/pp-2020.csv\", names=LReg_Names, usecols=usecols) \n",
    "LReg_Data2021 = pd.read_csv(root_path + \"LandReg/pp-2021.csv\", names=LReg_Names, usecols=usecols)\n",
    "\n",
    "LReg_Data = pd.concat([LReg_Data2020, LReg_Data2021])\n",
    "\n",
    "#remove the spaces from the postcode\n",
    "LReg_Data[\"Postcode\"] = LReg_Data[\"Postcode\"].astype(str).str.replace(\" \",\"\")\n",
    "\n",
    "LReg_Data = LReg_Data.merge(Points_of_Interest.loc[Points_of_Interest[\"Type\"]==\"Postcodes\", [\"Name\", \"Easting\", \"Northing\"]], left_on=\"Postcode\", right_on=\"Name\")\n",
    "\n",
    "LReg_Data[\"Details_Str\"] = np.column_stack((LReg_Data[\"Date_of_Transfer\"].to_numpy(),\n",
    "    LReg_Data[\"Property_Type\"].to_numpy(), \n",
    "    LReg_Data[\"Old_New\"].to_numpy(), \n",
    "    LReg_Data[\"Duration\"].to_numpy())\n",
    "    ).tolist()\n",
    "\n",
    "LReg_Data[\"Details_Float\"] = LReg_Data[\"Price\"]\n",
    "LReg_Data[\"Name\"] = LReg_Data[\"Transaction_unique_identifier\"]\n",
    "LReg_Data[\"Type\"] = \"LReg\"\n",
    "LReg_Data = LReg_Data.loc[:, [\"Type\", \"Name\", \"Details_Str\", \"Details_Float\", \"Easting\", \"Northing\"]]\n",
    "\n",
    "Points_of_Interest = Points_of_Interest.append(LReg_Data, ignore_index=True)\n",
    "del LReg_Data, LReg_Data2020, LReg_Data2021, LReg_Names, usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firestation Data\n",
    "FireStations = pd.read_excel(root_path + \"Fire_data/\" + \"fire-stations-dataset-121120.ods\", \n",
    "                         engine=\"odf\",\n",
    "                        sheet_name = \"STATIONS\")\n",
    "\n",
    "FireStations[\"Type\"] = \"FireStations\"\n",
    "FireStations[\"Name\"] = FireStations[\"STATION_NAME\"]\n",
    "FireStations[\"Easting\"] = FireStations[\"STATION_EASTING\"]\n",
    "FireStations[\"Northing\"] = FireStations[\"STATION_NORTHING\"]\n",
    "FireStations = FireStations.loc[:, [\"Type\", \"Name\", \"Easting\", \"Northing\"]]\n",
    "\n",
    "Points_of_Interest = Points_of_Interest.append(FireStations, ignore_index=True)\n",
    "del FireStations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schools Data\n",
    "usecols=[\"Postcode\", \"EstablishmentName\", \"EstablishmentTypeGroup (name)\"]\n",
    "Schools =pd.read_csv(root_path+\"Schools/\"+\"results.csv\", encoding = \"ISO-8859-1\", low_memory=False, usecols=usecols)\n",
    "\n",
    "#remove the spaces from the postcode\n",
    "Schools[\"Postcode\"] = Schools[\"Postcode\"].astype(str).str.replace(\" \",\"\")\n",
    "\n",
    "Schools = Schools.merge(Points_of_Interest.loc[Points_of_Interest[\"Type\"]==\"Postcodes\", [\"Name\", \"Easting\", \"Northing\"]], left_on=\"Postcode\", right_on=\"Name\")\n",
    "\n",
    "Schools[\"Type\"] = \"Schools\"\n",
    "Schools[\"Details_Str\"] = Schools[\"EstablishmentTypeGroup (name)\"]\n",
    "Schools[\"Name\"] = Schools[\"EstablishmentName\"]\n",
    "Schools = Schools.loc[:, [\"Type\", \"Name\", \"Details_Str\",\"Easting\", \"Northing\"]]\n",
    "\n",
    "Points_of_Interest = Points_of_Interest.append(Schools, ignore_index=True)\n",
    "del Schools, usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computer doesn't have enough ram to deal with UDPRN data so need to drop it here\n",
    "Points_of_Interest = Points_of_Interest[Points_of_Interest[\"Type\"]!=\"UDPRNs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We know that some of the easings and northings are on the Irish grid, split these out\n",
    "NI_Mask_1 = ((Points_of_Interest[\"Type\"]==\"Postcodes\") & (Points_of_Interest[\"Name\"].str.slice(stop=2)==\"BT\")).to_numpy()\n",
    "NI_Mask_2 =  ((Points_of_Interest[\"Type\"]==\"UDPRNs\") & (Points_of_Interest[\"Details_Str\"].str.slice(stop=2)==\"BT\")).to_numpy()\n",
    "NI_Mask = np.logical_or(NI_Mask_1, NI_Mask_2)\n",
    "\n",
    "NI = Points_of_Interest.loc[NI_Mask,:]\n",
    "Points_of_Interest = Points_of_Interest.loc[~NI_Mask,:]\n",
    "\n",
    "del NI_Mask_1, NI_Mask_2, NI_Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Geopandas dataframe\n",
    "x_points = Points_of_Interest[\"Easting\"].to_numpy()\n",
    "y_points = Points_of_Interest[\"Northing\"].to_numpy()\n",
    "\n",
    "raw_gdf = gpd.GeoDataFrame(Points_of_Interest.loc[:,[\"Type\", \"Name\", \"Details_Str\", \"Details_Float\"]], geometry=gpd.points_from_xy(x_points, y_points), crs=Main_CRS)\n",
    "del Points_of_Interest, x_points, y_points\n",
    "\n",
    "#Do the same for NI, and convert to the appropriate crs\n",
    "x_points = NI[\"Easting\"].to_numpy()\n",
    "y_points = NI[\"Northing\"].to_numpy()\n",
    "\n",
    "NI_gdf = gpd.GeoDataFrame(NI.loc[:,[\"Type\", \"Name\", \"Details_Str\", \"Details_Float\"]], geometry=gpd.points_from_xy(x_points, y_points), crs=\"EPSG:29902\")\n",
    "NI_gdf = NI_gdf.to_crs(Main_CRS)\n",
    "del NI, x_points, y_points\n",
    "\n",
    "#Re-combine now they are on the same coordinates\n",
    "raw_gdf = gpd.GeoDataFrame( pd.concat( [raw_gdf, NI_gdf], ignore_index=True) )\n",
    "del NI_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Police Crime data\n",
    "usecols = [\"Crime type\", \"Month\", \"Longitude\", \"Latitude\"]\n",
    "in_dtypes = {\"Crime type\":\"str\", \"Longitude\":np.float64, \"Latitude\":np.float64, \"Month\":\"str\"}\n",
    "\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(\"D:/GeoData/PoliceData/\"):\n",
    "    for name in files:\n",
    "        if name.endswith((\"street.csv\")):\n",
    "            file_list = file_list + [str(root) + \"/\" + str(name)]\n",
    "\n",
    "infile = file_list[0]\n",
    "\n",
    "Crimes = pd.read_csv(infile, encoding = \"ISO-8859-1\", dtype=in_dtypes, usecols=usecols)\n",
    "\n",
    "for file in file_list[1:]:\n",
    "    Crimes=Crimes.append(pd.read_csv(file, encoding = \"ISO-8859-1\", dtype=in_dtypes, usecols=usecols), ignore_index=True)\n",
    "\n",
    "Crimes = Crimes.dropna()\n",
    "Crimes = Crimes.rename(columns={\"Crime type\": \"Name\"})\n",
    "Crimes = Crimes.rename(columns={\"Month\": \"Details_Str\"})\n",
    "Crimes[\"Type\"] = \"Crimes\"\n",
    "\n",
    "#Police Stop and Search Data\n",
    "usecols = [\"Object of search\", \"Date\", \"Longitude\", \"Latitude\"]\n",
    "in_dtypes = {\"Object of search\":\"str\", \"Longitude\":np.float64, \"Latitude\":np.float64}\n",
    "\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(\"D:/GeoData/PoliceData/\"):\n",
    "    for name in files:\n",
    "        if name.endswith((\"search.csv\")):\n",
    "            file_list = file_list + [str(root) + \"/\" + str(name)]\n",
    "\n",
    "infile = file_list[0]\n",
    "\n",
    "StopAndSearch = pd.read_csv(infile, encoding = \"ISO-8859-1\", dtype=in_dtypes, usecols=usecols, parse_dates=[\"Date\"])\n",
    "\n",
    "for file in file_list[1:]:\n",
    "    StopAndSearch=StopAndSearch.append(pd.read_csv(file, encoding = \"ISO-8859-1\", dtype=in_dtypes, usecols=usecols, parse_dates=[\"Date\"]), ignore_index=True)\n",
    "\n",
    "StopAndSearch = StopAndSearch.dropna()\n",
    "StopAndSearch = StopAndSearch.rename(columns={\"Object of search\": \"Name\"})\n",
    "StopAndSearch[\"Date\"] = StopAndSearch[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "StopAndSearch = StopAndSearch.rename(columns={\"Date\": \"Details_Str\"})\n",
    "StopAndSearch[\"Type\"] = \"StopAndSearch\"\n",
    "\n",
    "Crimes = Crimes.append(StopAndSearch,ignore_index=True)\n",
    "del StopAndSearch\n",
    "\n",
    "#Convert to Geopandas dataframe\n",
    "x_points = Crimes[\"Longitude\"].to_numpy()\n",
    "y_points = Crimes[\"Latitude\"].to_numpy()\n",
    "\n",
    "crimes_gdf = gpd.GeoDataFrame(Crimes.loc[:,[\"Type\", \"Name\", \"Details_Str\"]], geometry=gpd.points_from_xy(x_points, y_points), crs=\"EPSG:4326\")\n",
    "crimes_gdf = crimes_gdf.to_crs(Main_CRS)\n",
    "crimes_gdf\n",
    "\n",
    "del Crimes\n",
    "\n",
    "#combine with the main points gdf\n",
    "raw_gdf = gpd.GeoDataFrame( pd.concat( [raw_gdf, crimes_gdf], ignore_index=True) )\n",
    "del crimes_gdf, file_list, infile, usecols, in_dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NHS Data\n",
    "\n",
    "usecols = [\"OrganisationType\", \"OrganisationName\", \"Longitude\", \"Latitude\"]\n",
    "in_dtypes = {\"OrganisationType\":\"str\", \"OrganisationName\":\"str\", \"Longitude\":np.float64, \"Latitude\":np.float64}\n",
    "\n",
    "NHS_list = [root_path + \"NHS/\" + str(i) for i in os.listdir(\"D:/GeoData/NHS\") if \".csv\" in i]\n",
    "\n",
    "NHS = pd.read_csv(NHS_list[0], sep='¬'  , engine='python', encoding = \"ISO-8859-1\", usecols=usecols, dtype=in_dtypes)\n",
    "\n",
    "for file in NHS_list[1:]:\n",
    "    NHS = NHS.append(pd.read_csv(file, sep='¬'  , engine='python', encoding = \"ISO-8859-1\", usecols=usecols, dtype=in_dtypes), ignore_index=True)\n",
    "\n",
    "NHS = NHS.rename(columns={\"OrganisationType\":\"Type\", \"OrganisationName\":\"Name\"})\n",
    "\n",
    "#Convert to Geopandas dataframe\n",
    "x_points = NHS[\"Longitude\"].to_numpy()\n",
    "y_points = NHS[\"Latitude\"].to_numpy()\n",
    "\n",
    "NHS_gdf = gpd.GeoDataFrame(NHS.loc[:,[\"Type\", \"Name\"]], geometry=gpd.points_from_xy(x_points, y_points), crs=\"EPSG:4326\")\n",
    "NHS_gdf = NHS_gdf.to_crs(Main_CRS)\n",
    "NHS_gdf\n",
    "\n",
    "del NHS\n",
    "\n",
    "raw_gdf = gpd.GeoDataFrame(pd.concat( [raw_gdf, NHS_gdf], ignore_index=True) )\n",
    "\n",
    "del NHS_gdf, usecols, in_dtypes, NHS_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shape_Loc = {\n",
    "    'All_GB' : [root_path + \"Countries__December_2019__Boundaries_UK_BFC-shp/Countries__December_2019__Boundaries_UK_BFC.shp\", \"ctry19nm\"],\n",
    "    'National_Parks' : [root_path + \"National_Parks__December_2019__GB_BFE-shp/National_Parks__December_2019__GB_BFE.shp\", \"NPARK19NM\"],\n",
    "    'LocalAuthorities' : [root_path + \"Local_Authority_Districts__May_2020__Boundaries_UK_BFC-shp/Local_Authority_Districts__May_2020__Boundaries_UK_BFC.shp\", \"LAD20NM\"],\n",
    "    'LSOA' : [root_path + \"Lower_Layer_Super_Output_Area__December_2011__EW_BSC_V2-shp/Lower_Layer_Super_Output_Area__December_2011__EW_BSC_V2.shp\", \"LSOA11NMW\"],\n",
    "    'GreenSpace' : [root_path + \"opgrsp_essh_gb/OS Open Greenspace (ESRI Shape File) GB/data/GB_GreenspaceSite.shp\", \"id\"],\n",
    "    'Rivers' : [root_path + \"oprvrs_essh_gb/data/WatercourseLink.shp\",\"name1\"],\n",
    "    'Railway_Lines' : [root_path + \"strtgi_essh_gb/data/railway_line.shp\",\"LEGEND\"],\n",
    "    'Woodland_Region' : [root_path + \"strtgi_essh_gb/data/woodland_region.shp\",\"LEGEND\"],\n",
    "    'Urban_Region' : [root_path + \"strtgi_essh_gb/data/urban_region.shp\",\"LEGEND\"],\n",
    "    'Foreshor_Region' : [root_path + \"strtgi_essh_gb/data/foreshor_region.shp\",\"LEGEND\"],\n",
    "    'Ferry_Line' : [root_path + \"strtgi_essh_gb/data/ferry_line.shp\",\"LEGEND\", [\"FERRY_TIME\", \"FERRY_TYPE\", \"RESTRICTIO\", \"ACCESS\"]],\n",
    "    'Coastline' : [root_path + \"strtgi_essh_gb/data/coastline.shp\",\"LEGEND\"],\n",
    "    'Lakes' : [root_path + \"strtgi_essh_gb/data/lakes_region.shp\", \"LEGEND\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getextra(list):\n",
    "    try:\n",
    "        extra = list[2]\n",
    "        extraexists = True\n",
    "    except:\n",
    "        extra = []\n",
    "        extraexists = False\n",
    "\n",
    "    return extra, extraexists\n",
    "\n",
    "def get_shapefile(v):\n",
    "    extra, extraexists = getextra(v)\n",
    "    gdf = gpd.read_file(v[0]).to_crs(Main_CRS).loc[:,[v[1], \"geometry\"]+extra]\n",
    "    gdf = gdf.rename(columns={v[1]: \"Name\"})\n",
    "    gdf[\"Type\"] = k\n",
    "\n",
    "    usecols = [\"Type\", \"Name\", \"geometry\"]\n",
    "\n",
    "    if extraexists:\n",
    "        array = gdf[extra[0]].to_numpy()\n",
    "        if len(extra)>1:\n",
    "            for e in extra[1:]:\n",
    "                array = np.column_stack((array,gdf[e].to_numpy()))\n",
    "        gdf[\"Details_Str\"] = array.tolist()\n",
    "        usecols = usecols + [\"Details_Str\"]\n",
    "\n",
    "    gdf = gdf[usecols]\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all of the shape files to the master list\n",
    "\n",
    "for k in Shape_Loc.keys():\n",
    "    v = Shape_Loc[k]\n",
    "    raw_gdf = gpd.GeoDataFrame(pd.concat( [raw_gdf, get_shapefile(v)], ignore_index=True) )\n",
    "\n",
    "del Shape_Loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the roads\n",
    "file = os.listdir(\"D:\\GeoData\\oproad_essh_gb\\data\")\n",
    "ignore_cols = [\"fictitious\", \"identifier\", \"name1_lang\", \"name2\", \"name2_lang\", \"formOfWay\", \"length\", \"primary\", \"trunkRoad\", \"loop\", \"startNode\", \"endNode\", \"structure\", \"nameTOID\", \"numberTOID\", \"function\"]\n",
    "\n",
    "path = [os.path.join(\"D:\\GeoData\\oproad_essh_gb\\data\", i) for i in file if \"RoadLink.shp\" in i]\n",
    "\n",
    "Roads = gpd.GeoDataFrame(pd.concat([gpd.read_file(i, ignore_fields=ignore_cols) for i in path], ignore_index=True), crs=Main_CRS)\n",
    "\n",
    "Roads[\"Type\"] = \"Road\"\n",
    "Roads = Roads.rename(columns={\"class\": \"Name\"})\n",
    "Roads = Roads.rename(columns={\"roadNumber\": \"Details_Str\"})\n",
    "Roads.loc[Roads[\"Details_Str\"].isnull(),\"Details_Str\"] = Roads[\"name1\"]\n",
    "Roads = Roads.drop(columns=[\"name1\"])\n",
    "\n",
    "raw_gdf = gpd.GeoDataFrame(pd.concat( [raw_gdf, Roads], ignore_index=True) )\n",
    "del Roads, ignore_cols, path\n",
    "\n",
    "#Add the motorway junctions\n",
    "path = [os.path.join(\"D:\\GeoData\\oproad_essh_gb\\data\", i) for i in file if \"MotorwayJunction.shp\" in i]\n",
    "\n",
    "MotorwayJunctions = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path],  ignore_index=True), crs=Main_CRS)\n",
    "\n",
    "MotorwayJunctions = MotorwayJunctions.drop(columns=\"identifier\")\n",
    "MotorwayJunctions = MotorwayJunctions.rename(columns={\"number\": \"Name\"})\n",
    "MotorwayJunctions[\"Type\"] = \"MotorwayJunction\"\n",
    "\n",
    "raw_gdf = gpd.GeoDataFrame(pd.concat( [raw_gdf, MotorwayJunctions], ignore_index=True) )\n",
    "del MotorwayJunctions, path, file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Natural England data\n",
    "NE_Data = {\n",
    "    \"NE_Peat\" : {\"url\":\"https://opendata.arcgis.com/datasets/55b21c31a61c4292a465d7618d831eb8_0.geojson\", \"Type\":\"Peat\", \"Name\":\"PCLASSDESC\", \"Details_Str\":\"Type\", \"geometry\":\"geometry\"},\n",
    "    \"NE_SSI\" : {\"url\":\"https://opendata.arcgis.com/datasets/03fd7a2f8e4e4346bf41ce7879153949_0.geojson\", \"Type\":\"SiteOfScientificInterest\", \"Name\":\"SSSI_NAME\", \"Details_Str\":\"OBJECTID\", \"geometry\":\"geometry\"},\n",
    "    \"NE_LocalNatureReserve\" : {\"url\":\"https://opendata.arcgis.com/datasets/b1d690ac6dd54c15bdd2d341b686ecd7_0.geojson\", \"Type\":\"LocalNatureReserve\", \"Name\":\"LNR_NAME\", \"Details_Str\":\"OBJECTID\", \"geometry\":\"geometry\"},\n",
    "    \"NE_NationalNatureReserve\" : {\"url\":\"https://opendata.arcgis.com/datasets/ab7bfd86f5b347df8d47fc9bfab80caf_0.geojson\", \"Type\":\"NationalNatureReserve\", \"Name\":\"NNR_NAME\", \"Details_Str\":\"OBJECTID\", \"geometry\":\"geometry\"},\n",
    "    \"NE_SpecialAreaOfConvervation\" : {\"url\":\"https://opendata.arcgis.com/datasets/e4142658906c498fa37f0a20d3fdfcff_0.geojson\", \"Type\":\"SpecialAreaOfConservation\", \"Name\":\"SAC_NAME\", \"Details_Str\":\"SAC_CODE\", \"geometry\":\"geometry\"},\n",
    "    \"NE_AncientWoodland\" : {\"url\":\"https://opendata.arcgis.com/datasets/a14064ca50e242c4a92d020764a6d9df_0.geojson\", \"Type\":\"AncientWoodland\", \"Name\":\"NAME\", \"Details_Str\":\"THEMNAME\", \"geometry\":\"geometry\"}\n",
    "}\n",
    "\n",
    "def get_NE_Data(details):\n",
    "    url = details[\"url\"]\n",
    "\n",
    "    usecols = [details[\"Name\"], details[\"Details_Str\"], details[\"geometry\"]]\n",
    "\n",
    "    gdf = gpd.read_file(url).to_crs(Main_CRS).loc[:, usecols]\n",
    "\n",
    "\n",
    "    gdf = gdf.rename(columns={details[\"Name\"]: \"Name\"})\n",
    "    gdf = gdf.rename(columns={details[\"Details_Str\"]: \"Details_Str\"})\n",
    "    gdf = gdf.rename(columns={details[\"geometry\"]: \"geometry\"})\n",
    "    gdf[\"Type\"] = details[\"Type\"]\n",
    "\n",
    "    return gdf\n",
    "\n",
    "for k in NE_Data.keys():\n",
    "    v = NE_Data[k]\n",
    "    raw_gdf = gpd.GeoDataFrame(pd.concat( [raw_gdf, get_NE_Data(v)], ignore_index=True) )\n",
    "\n",
    "del NE_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Historic England Data\n",
    " \n",
    "path = root_path + \"HistoricEngland/Conservation Areas/20210922_Conservation_Areas_INSPIRE_dataset.shp\"\n",
    "HE_gdf = gpd.read_file(path).loc[:,[\"NAME\", \"geometry\"]].to_crs(Main_CRS)\n",
    "HE_gdf = HE_gdf.rename(columns={\"NAME\": \"Name\"})\n",
    "HE_gdf[\"Type\"] = \"ConservationArea\"\n",
    "\n",
    "path = root_path + \"HistoricEngland/Listed Buildings/ListedBuildings_12Jan2022.shp\"\n",
    "LB_gdf = gpd.read_file(path).loc[:,[\"Name\", \"Grade\", \"geometry\"]].to_crs(Main_CRS)\n",
    "LB_gdf = LB_gdf.rename(columns={\"Grade\": \"Details_Str\"})\n",
    "LB_gdf[\"Type\"] = \"Listed Buildings\"\n",
    "\n",
    "HE_gdf = gpd.GeoDataFrame(pd.concat( [HE_gdf, LB_gdf], ignore_index=True) )\n",
    "del LB_gdf\n",
    "\n",
    "raw_gdf = gpd.GeoDataFrame(pd.concat( [raw_gdf, HE_gdf], ignore_index=True) )\n",
    "del HE_gdf, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Met office data for 2020\n",
    "met_data = {\n",
    "    \"rainfall\":[\"MetOffice/rainfall_hadukgrid_uk_1km_ann_202001-202012.nc\", \"TotalRainfall_mm_2020\"],\n",
    "    \"snowLying\":[\"MetOffice/snowLying_hadukgrid_uk_1km_ann_202001-202012.nc\", \"Snow_Days_2020\"],\n",
    "    \"sun\":[\"MetOffice/sun_hadukgrid_uk_1km_ann_202001-202012.nc\", \"Sunlight_h_2020\"],\n",
    "    \"tas\":[\"MetOffice/tas_hadukgrid_uk_1km_ann_202001-202012.nc\", \"AverageTemperature_C_2020\"],\n",
    "    \"groundfrost\":[\"MetOffice/groundfrost_hadukgrid_uk_1km_ann_202001-202012.nc\", \"GroundFrost_Days_2020\"]\n",
    "    }\n",
    "\n",
    "def import_met(path, col, name):\n",
    "    pth = root_path +path\n",
    "    dnc = xr.open_dataset(pth)  \n",
    "    df = dnc.to_dataframe()\n",
    "\n",
    "    df = df.dropna().reset_index().loc[:, [\"projection_y_coordinate\", \"projection_x_coordinate\", col, \"bnds\"]]\n",
    "    df = df.loc[df[\"bnds\"]==0,:].drop(columns=\"bnds\").reset_index(drop=True)\n",
    "    df = df.rename(columns={col: \"Details_Float\"})\n",
    "    df[\"Name\"] = name\n",
    "    df[\"Type\"] = \"MetOffice\"\n",
    "\n",
    "    #Convert to Geopandas dataframe\n",
    "    x_points = df[\"projection_x_coordinate\"].to_numpy()\n",
    "    y_points = df[\"projection_y_coordinate\"].to_numpy()\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df.loc[:,[\"Details_Float\", \"Type\", \"Name\"]], geometry=gpd.points_from_xy(x_points, y_points), crs=Main_CRS)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "for k in met_data.keys():\n",
    "    raw_gdf = gpd.GeoDataFrame(pd.concat( [raw_gdf, import_met(met_data[k][0], k, met_data[k][1])], ignore_index=True) )\n",
    "\n",
    "del met_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove invalid geometeries\n",
    "raw_gdf = raw_gdf[raw_gdf.is_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gdf.to_pickle(root_path + 'WorkingData/' + 'raw_gdf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePolygon(centre, sq_sz, inp_crs):\n",
    "    mnx = centre[0]-(sq_sz/2)\n",
    "    mny = centre[1]-(sq_sz/2)\n",
    "    mxx = centre[0]+(sq_sz/2)\n",
    "    mxy = centre[1]+(sq_sz/2)\n",
    "    polygon =Polygon([(mnx, mny), (mnx,mxy), (mxx,mxy), (mxx,mny), (mnx, mny)])\n",
    "    poly_gdf = gpd.GeoDataFrame(geometry=[polygon], crs=inp_crs)\n",
    "    return poly_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_clip(name):\n",
    "    poly = MakePolygon(KeyLocations[name], 5000, Main_CRS)\n",
    "    simple = gpd.clip(raw_gdf, poly)\n",
    "    simple.to_pickle(root_path + 'WorkingData/' + 'raw_gdf_' + name + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyLocations = {'Grasmere': [334692 , 506545],\n",
    "    'South_London' : [535493, 171250],\n",
    "    'Loch_Lomond' : [238450 , 690986],\n",
    "    'Furness' : [326877 , 474372],\n",
    "    'Croydon' : [532621 , 165313],\n",
    "    'StPauls' : [532052 , 181145],\n",
    "    'M25' : [503078 , 178200],\n",
    "    'M4_junct' : [519377 , 178360],\n",
    "    'M6_Junctions' : [357659 , 425462],\n",
    "    'Kendal': [353086 , 492882],\n",
    "    'Milford Haven': [190649 , 205747],\n",
    "    'Birmingham':[409295 , 290319],\n",
    "    'Euston':[529947 , 182697],\n",
    "    'Southampton':[441934 , 111013],\n",
    "    'Windermere': [341217 , 498029],\n",
    "    'Avonmouth': [351730 , 178243]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in KeyLocations.keys():\n",
    "    simple_clip(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gdf[\"Type\"].dropna().unique().tolist()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f78a45328dcddc684fcc7e97834e2f9ed1c731cb5e93878b3fdd5359bd832b4d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('GeoData': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
